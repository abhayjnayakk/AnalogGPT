"""
Topology Generator â€“ Domain-Specific LLM placeholder.

This module pretends to wrap a custom Transformer that synthesises SPICE
topologies from text specifications.

TODO: Replace mocked generate() with real inference once the model is trained.
"""

from dataclasses import dataclass
from typing import List
import random
import textwrap

# Mock library of hard-coded cells for investor demo
DEVICE_LIB = [
    "M1 OUT IN GND GND nch W=10u L=65n",
    "M2 OUT IN VDD VDD pch W=20u L=65n",
    "R1 OUT 0 10k",
    "C1 OUT 0 1p",
]


@dataclass
class TopologyLLM:
    model_name: str = "schmitt-gpt-1.2B"
    temperature: float = 0.7

    def generate(self, spec: str) -> List[str]:
        """Return a list of SPICE statements (netlist fragment)."""
        random.seed(hash(spec) % (2**32))
        k = random.randint(2, 5)
        lines = random.sample(DEVICE_LIB, k=k)
        comment = f"* Generated by {self.model_name}"
        return [comment] + lines

    def explain(self, spec: str) -> str:
        """Return a high-level natural language explanation."""
        return textwrap.dedent(
            f"""
            I interpreted the spec "{spec}" and produced a differential pair
            front-end followed by a load resistor. This is a **placeholder**
            explanation; future versions will cite relevant gm/Id trade-offs
            and stability criteria.
            """
        ).strip() 